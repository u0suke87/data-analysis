{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from chainer import cuda, Variable, FunctionSet, optimizers\n",
    "import chainer.functions as F\n",
    "from sklearn.cross_validation import KFold\n",
    "import sys\n",
    "import csv\n",
    "from pprint import pprint \n",
    "\n",
    "plt.style.use('ggplot')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# 確率的勾配降下法におけるミニバッチ数\n",
    "batchsize = 20\n",
    "\n",
    "# 学習の繰り返し回数\n",
    "n_epoch = 50\n",
    "\n",
    "# 中間層の数\n",
    "n_units = 20\n",
    "\n",
    "\n",
    "#=================================================\n",
    "# csvファイルからデータを取り出し、listに格納\n",
    "def set_data():\n",
    "\n",
    "        filename = \"../../../data/secondary_selection/input_data2_2\"\n",
    "        \n",
    "        f = open('%s.csv' % filename, 'rU')\n",
    "        data = csv.reader(f)\n",
    "\n",
    "        data_set = []\n",
    "        target_set = []\n",
    "        for line in data:\n",
    "                data_set.append(line[1:16])\n",
    "                target_set.append(line[16])\n",
    "        f.close()\n",
    "        np_dataSet = np.array(data_set, dtype=np.float32)\n",
    "        np_targetSet = np.array(target_set, dtype=np.int32)\n",
    "        return np_dataSet, np_targetSet\n",
    "\n",
    "#=================================================\n",
    "\n",
    "data, target = set_data()\n",
    "\n",
    "# <!--- start_debug\n",
    "#print data.shape\n",
    "#print target.shape\n",
    "#       end_debug ----> \n",
    "\n",
    "\n",
    "# 学習用データをN個、検証用データを残りの個数と設定\n",
    "# Nの値は暫定的なもの\n",
    "#N = 300\n",
    "#x_train, x_test = np.split( data, [N])  \n",
    "#y_train, y_test = np.split( target, [N]) \n",
    "#N_test = y_test.size\n",
    "#print data\n",
    "#print target\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# 多層パーセプトロンモデルの設定\n",
    "# 入力 15次元、出力 2次元\n",
    "model = FunctionSet(l1=F.Linear(15, n_units),\n",
    "                    l2=F.Linear(n_units, n_units),\n",
    "                    l3=F.Linear(n_units, n_units),\n",
    "                    l4=F.Linear(n_units, 2))\n",
    "\n",
    "# Neural net architecture\n",
    "# ニューラルネットの構造\n",
    "def forward(x_data, y_data, train=True ):\n",
    "        x, t = Variable(x_data), Variable(y_data)\n",
    "        h1 = F.dropout(F.relu(model.l1(x)), ratio=.4, train=train)\n",
    "        h2 = F.dropout(F.relu(model.l2(h1)), ratio=.4, train=train)\n",
    "        h3 = F.dropout(F.relu(model.l3(h2)), ratio=.4, train=train)\n",
    "        y = model.l4(h3)\n",
    "        # 0/1の2クラス分類なので誤差関数として、ソフトマックス関数\n",
    "        # を用いて、誤差を導出\n",
    "   \n",
    "                                \n",
    "        #print '-'*50\n",
    "        #print ' h3'\n",
    "        #print '-'*50\n",
    "        #print vars(h3)\n",
    "                        \n",
    "        #print '-'*50\n",
    "        #print ' y'\n",
    "        #print '-'*50\n",
    "        #print vars(y)\n",
    " \n",
    "        \n",
    "        return F.softmax_cross_entropy(y, t), F.accuracy(y, t), F.recall(y, t), F.precision(y, t)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Setup optimizer\n",
    "optimizer = optimizers.Adam()\n",
    "optimizer.setup(model)\n",
    "\n",
    "train_loss = []\n",
    "train_acc= []\n",
    "train_rec = []\n",
    "train_pre = []\n",
    "test_loss = []\n",
    "test_acc = []\n",
    "test_rec = []\n",
    "test_pre = []\n",
    "\n",
    "l1_W = []\n",
    "l2_W = []\n",
    "l3_W = []\n",
    "l4_W = []\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 1\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "need more than 4 values to unpack",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-5-7617575a92b2>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     50\u001b[0m                     \u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mzero_grads\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     51\u001b[0m                     \u001b[0;31m# 順伝播させて誤差と精度を算出\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 52\u001b[0;31m                     \u001b[0mloss\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0macc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrec\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrec_size\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpre\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpre_size\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx_batch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_batch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     53\u001b[0m                     \u001b[0;31m# 誤差逆伝播で勾配を計算\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     54\u001b[0m                     \u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: need more than 4 values to unpack"
     ]
    }
   ],
   "source": [
    "#インプットデータ総数\n",
    "n_kf = 400\n",
    "#fold数\n",
    "n_kf_folds = 4\n",
    "#trainデータ数\n",
    "N = n_kf  *  (( n_kf_folds-1)*1.0 / n_kf_folds)\n",
    "N = int(N)\n",
    "#testデータ数\n",
    "N_test = n_kf - N\n",
    "\n",
    "#cv配列初期化\n",
    "total_train_loss = [0] * n_epoch\n",
    "total_train_acc = [0] * n_epoch\n",
    "total_train_rec = [0] * n_epoch\n",
    "total_train_pre = [0] * n_epoch\n",
    "total_test_loss = [0] * n_epoch\n",
    "total_test_acc = [0] * n_epoch\n",
    "total_test_rec = [0] * n_epoch\n",
    "total_test_pre = [0] * n_epoch\n",
    "\n",
    "\n",
    "\n",
    "kf = KFold(n=n_kf, n_folds=n_kf_folds)\n",
    "\n",
    "for kf_train_index, kf_test_index in kf:\n",
    "\n",
    "    #print kf_train_index[perm[0:15]]\n",
    "    \n",
    "    #print kf_train_index\n",
    "    \n",
    "    # Learning loop\n",
    "    for epoch in xrange(1, n_epoch+1):\n",
    "            print 'epoch', epoch\n",
    "\n",
    "            # training\n",
    "            # N個の順番をランダムに並び替える\n",
    "            perm = np.random.permutation(N)\n",
    "            sum_accuracy = 0\n",
    "            sum_loss = 0\n",
    "            sum_recall = 0\n",
    "            sum_precision = 0\n",
    "            total_rec_size = 0\n",
    "            total_pre_size = 0\n",
    "            # 0〜Nまでのデータをバッチサイズごとに使って学習\n",
    "            for i in xrange(0, N, batchsize):\n",
    "                    x_batch = data[kf_train_index[perm[i:i+batchsize]]]\n",
    "                    y_batch = target[kf_train_index[perm[i:i+batchsize]]]\n",
    "\n",
    "                    # 勾配を初期化\n",
    "                    optimizer.zero_grads()\n",
    "                    # 順伝播させて誤差と精度を算出\n",
    "                    loss, acc, rec, pre = forward(x_batch, y_batch)\n",
    "                    # 誤差逆伝播で勾配を計算\n",
    "                    loss.backward()\n",
    "                    optimizer.update()\n",
    "        \n",
    "                    sum_loss += float(cuda.to_cpu(loss.data)) * batchsize\n",
    "                    sum_accuracy += float(cuda.to_cpu(acc.data)) * batchsize\n",
    "                    sum_recall += float(cuda.to_cpu(rec.data[0])) * rec.data[1]\n",
    "                    sum_precision += float(cuda.to_cpu(pre.data[0])) * pre.data[1]\n",
    "                    total_rec_size += rec.data[1]\n",
    "                    total_pre_size += pre.data[1]\n",
    "    \n",
    "            # 訓練データの誤差と、正解精度を表示\n",
    "            #print 'train mean loss={}, accuracy={}, recall={}, precision={}'.format(sum_loss / N, sum_accuracy / N, sum_recall / N, sum_precision / N)\n",
    "                \n",
    "            total_train_loss[epoch-1] += (sum_loss / (N * n_kf_folds))\n",
    "            total_train_acc[epoch-1] += (sum_accuracy / (N * n_kf_folds))\n",
    "            total_train_rec[epoch-1] += (sum_recall / (total_rec_size * n_kf_folds))\n",
    "            total_train_pre[epoch-1] += (sum_precision / (total_pre_size * n_kf_folds))\n",
    "\n",
    "\n",
    "            # evaluation\n",
    "            # テストデータで誤差と、正解精度を算出し汎化性能を確認\n",
    "            sum_accuracy = 0\n",
    "            sum_loss     = 0\n",
    "            sum_recall = 0\n",
    "            sum_precision = 0\n",
    "            total_rec_size = 0\n",
    "            total_pre_size = 0\n",
    "            for i in xrange(0, N_test, batchsize):\n",
    "                    x_batch = data[kf_test_index[i:i+batchsize]]\n",
    "                    y_batch = target[kf_test_index[i:i+batchsize]]\n",
    "\n",
    "                    # 順伝播させて誤差と精度を算出\n",
    "                    loss, acc, rec, pre = forward(x_batch, y_batch, train=False)\n",
    "          \n",
    "                    #print( cuda.to_cpu(loss.data))\n",
    "                    #print( cuda.to_cpu(rec.data))\n",
    "                    #print( cuda.to_cpu(pre.data))\n",
    "                    sum_loss     += float(cuda.to_cpu(loss.data)) * batchsize\n",
    "                    sum_accuracy += float(cuda.to_cpu(acc.data)) * batchsize\n",
    "                    sum_recall += float(cuda.to_cpu(rec.data[0])) * rec.data[1]\n",
    "                    sum_precision += float(cuda.to_cpu(pre.data[0])) * pre.data[1]\n",
    "                    total_rec_size += rec.data[1]\n",
    "                    total_pre_size += pre.data[1]\n",
    "                \n",
    "\n",
    "            # テストデータでの誤差と、正解精度を表示\n",
    "            #print 'test  mean loss={}, accuracy={}, recall={}, precision={}'.format(sum_loss / N_test, sum_accuracy / N_test, sum_recall / N_test, sum_precision / N_test)\n",
    "            #test_loss.append( sum_loss / N_test)\n",
    "            #test_acc.append( sum_accuracy / N_test)\n",
    "            #test_rec.append(sum_recall / N_test)\n",
    "            #test_pre.append(sum_precision / N_test) \n",
    "            \n",
    "            \n",
    "            total_test_loss[epoch-1] += (sum_loss / (N_test * n_kf_folds))\n",
    "            total_test_acc[epoch-1] += (sum_accuracy / (N_test * n_kf_folds))\n",
    "            total_test_rec[epoch-1] += (sum_recall / (total_rec_size * n_kf_folds))\n",
    "            total_test_pre[epoch-1] += (sum_precision / (total_pre_size * n_kf_folds))\n",
    "        \n",
    "\n",
    "        \n",
    "            # 学習したパラメーターを保存\n",
    "            l1_W.append(model.l1.W)\n",
    "            l2_W.append(model.l2.W)\n",
    "            l3_W.append(model.l3.W)\n",
    "            l4_W.append(model.l4.W)\n",
    "        \n",
    "            #l1_W = np.append( l1_W, model.l1.W)\n",
    "        \n",
    "                      \n",
    "            #pprint(vars(model.l1))\n",
    "            #pprint(model.l1.W[0:2])\n",
    "\n",
    "        \n",
    "            \n",
    "# 精度と誤差をグラフ描画\n",
    "plt.figure(figsize=(8,6))\n",
    "plt.plot(range(len(total_train_acc)), total_train_acc)\n",
    "plt.plot(range(len(total_test_acc)), total_test_acc)\n",
    "plt.legend([\"total_train_acc\",\"total_test_acc\"],loc=4)\n",
    "plt.title(\"Accuracy of classification.\")\n",
    "plt.plot()\n",
    "\n",
    "\n",
    "plt.figure(figsize=(8,6))\n",
    "plt.plot(range(len(total_train_rec)), total_train_rec)\n",
    "plt.plot(range(len(total_test_rec)), total_test_rec)\n",
    "plt.legend([\"total_train_rec\",\"total_test_rec\"],loc=4)\n",
    "plt.title(\"Recall of classification.\")\n",
    "plt.plot()\n",
    "\n",
    "\n",
    "plt.figure(figsize=(8,6))\n",
    "plt.plot(range(len(total_train_pre)), total_train_pre)\n",
    "plt.plot(range(len(total_test_pre)), total_test_pre)\n",
    "plt.legend([\"total_train_pre\",\"total_test_pre\"],loc=4)\n",
    "plt.title(\"Precision of classification.\")\n",
    "plt.plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[-0.02798676 -0.17780033]\n",
      " [ 0.247187    0.10619548]\n",
      " [ 0.27062398 -0.05198815]\n",
      " [-0.01262167 -0.25728923]\n",
      " [ 0.53304344  0.21175373]\n",
      " [-0.11098442  0.12040781]\n",
      " [-0.21507969 -0.11726713]\n",
      " [-0.47144216  0.0398447 ]\n",
      " [-0.16562846 -0.2208975 ]\n",
      " [ 0.69890964  0.43969148]\n",
      " [-0.24674706  0.07255423]\n",
      " [ 0.24821234 -0.06143026]\n",
      " [-0.02372829  0.29510057]\n",
      " [ 0.05651759  0.24108914]\n",
      " [-0.36914977  0.33070898]]\n"
     ]
    }
   ],
   "source": [
    "# 学習したパラメータを出力\n",
    "#print l1_W\n",
    "\n",
    "#print l2_W\n",
    "#print l3_W\n",
    "\n",
    "l1 = l1_W[0].T\n",
    "l2 = l2_W[0].T\n",
    "l3 = l3_W[0].T\n",
    "l4 = l4_W[0].T\n",
    "\n",
    "\n",
    "param = l1.dot(l2).dot(l3).dot(l4)\n",
    "\n",
    "print param"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.8474999944368998, 0.874166662991047, 0.8841666628917059, 0.8883333290616672, 0.9041666626930237, 0.9024999956289927, 0.9233333279689153, 0.9233333299557368, 0.9299999982118607, 0.9408333281675975, 0.9416666636864344, 0.9458333273728688, 0.9524999976158142, 0.9374999970197677, 0.9466666628917058, 0.9516666620969771, 0.9508333285649617, 0.947499997417132, 0.9549999972184499, 0.9499999970197677, 0.9574999948342641, 0.9608333289623261, 0.962499996026357, 0.9608333289623261, 0.9583333263794581, 0.968333328763644, 0.9608333299557368, 0.9666666607062022, 0.9658333291610082, 0.9641666620969773, 0.9616666595141092, 0.9741666624943415, 0.9741666615009308, 0.9816666622956594, 0.9633333285649617, 0.9741666634877524, 0.9699999968210857, 0.976666663090388, 0.9741666615009307, 0.9683333287636439, 0.975833327571551, 0.9741666624943417, 0.9741666624943415, 0.9758333295583725, 0.9749999950329463, 0.9691666622956594, 0.977499994635582, 0.9741666615009308, 0.9741666624943415, 0.9774999966224034]\n"
     ]
    }
   ],
   "source": [
    "print total_train_acc"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "pprint(vars(model.l1))\n",
    "pprint(vars(model.l2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
